{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abandoned-stanley",
   "metadata": {},
   "source": [
    "# Final Model Iteration\n",
    "\n",
    "The purpose of this notebook is to demonstrate training using tensorflow 2 and keras. This notebook includes tf Data pipelines for build any other NLP task in a text to text fashion. Anyone can adapt the data pipeline to thier own datasets. Uses the efficient [Datasets](https://github.com/huggingface/datasets) from ðŸ¤— as source for training.\n",
    "\n",
    "#### Features:\n",
    "- Train TF T5 on E2E Cleaned Data to Text Problem\n",
    "- Train T5 using keras trainer fucntion\n",
    "- tf.Data pipeline\n",
    "- [Datasets from ðŸ¤—](https://github.com/huggingface/datasets) as source\n",
    "- Log metrics using tensorboard\n",
    "- Profile your experiment with the brand new tensorflow profiler !!\n",
    "\n",
    "#### Steps:\n",
    "* Import Libraries\n",
    "* Load Train/Dev/Test Data\n",
    "* Config Definitions\n",
    "* Pre-process Data (Tensors)\n",
    "* Quick Tensor EDA\n",
    "* Tensorboard Loading\n",
    "* Optimizer Init\n",
    "* Train Model\n",
    "* Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-cardiff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import traceback\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "#NLTK \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "#HuggingFace\n",
    "import transformers\n",
    "from transformers import (TFAutoModelWithLMHead, AutoTokenizer,\n",
    "                            TFTrainer, TFTrainingArguments, T5Tokenizer, TFT5ForConditionalGeneration,\n",
    "                            TFT5Model, T5Config, pipeline)\n",
    "import datasets\n",
    "from datasets import load_dataset, list_datasets\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "#AWS\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.getcwd()\n",
    "print(\"Experiment Dir: \", exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir, os.pardir, os.pardir))\n",
    "os.chdir(base_dir)\n",
    "print(\"Base Dir: \", base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Utils Lib\n",
    "from src.utils.utils import (get_model_output, write_model_output, save_metrics,\n",
    "                         encode, to_tf_dataset, create_dataset, compute_metrics, save_model_to_s3)\n",
    "from src.classes.t5Wrapper import T5Wrapper\n",
    "from src.classes.customScheduler import CustomSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)\n",
    "\n",
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-classics",
   "metadata": {},
   "source": [
    "### Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS box path we should keep\n",
    "tb_data_dir = f\"{exp_dir}/tf_data\"\n",
    "log_dir = f\"{tb_data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{tb_data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{tb_data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{tb_data_dir}/cache/t5.test\"\n",
    "\n",
    "print(\"Experiment Base directory: \",exp_dir)\n",
    "model_path = f'{exp_dir}/model'\n",
    "print('model_path: ', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-stranger",
   "metadata": {},
   "source": [
    "### Load Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('e2e_nlg_cleaned', split='train')\n",
    "validation = load_dataset('e2e_nlg_cleaned', split='validation')\n",
    "\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-venice",
   "metadata": {},
   "source": [
    "### Init Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_back_epochs = 5\n",
    "batch_size = 30\n",
    "buffer_size = 1000\n",
    "ntrain = len(train)\n",
    "nvalid = len(validation)\n",
    "steps = int((ntrain//fall_back_epochs)// batch_size)\n",
    "valid_steps = int((nvalid//fall_back_epochs)// batch_size)\n",
    "\n",
    "print(\"Train Data Length: \", ntrain)\n",
    "print(\"Validation Data Length: \", nvalid)\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "print(\"Total fall_back_epochs: \", fall_back_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-certificate",
   "metadata": {},
   "source": [
    "### Model Variants and Param Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{base_dir}/src/experiments/model_training_experiment/exp_chpt/result_271.txt'\n",
    "with open(path) as json_file:\n",
    "    models_data = json.load(json_file)\n",
    "    \n",
    "path = f'{exp_dir}/param_sets.txt'\n",
    "with open(path) as json_file:\n",
    "    param_sets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-yahoo",
   "metadata": {},
   "source": [
    "### Model Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "praveen = [172, 247, 157]\n",
    "karthik = [67, 82]\n",
    "\n",
    "id_set = set(karthik)\n",
    "model_variants = [model for model in models_data if model['id'] in id_set]\n",
    "print(\"Number of variants: \", len(model_variants))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-coating",
   "metadata": {},
   "source": [
    "### Param Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of param_sets: \", len(param_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_generation(model, tokenizer):\n",
    "    global tf_valid_ds\n",
    "    global validation\n",
    "    global exp_dir\n",
    "    global base_dir\n",
    "    global param_sets\n",
    "    \n",
    "    print(\"Starting Generate Variants:\")\n",
    "    param_count = 1\n",
    "    for param_set in param_sets:\n",
    "        \n",
    "#         ### IF SOMETHING BREAKS PICKUP WHERE WE LEFT OFF\n",
    "#         if param_count < PICK_THE_NUM:\n",
    "#             print(f'Skipping: Model#: {model_count} Param#: {param_count}')\n",
    "#             param_count +=1\n",
    "#             continue\n",
    "#         ###\n",
    "        \n",
    "        print(f\"Generate {param_count}/{len(param_sets)}\")\n",
    "        print(str(param_set))\n",
    "\n",
    "        #Returns a list of all the model generated outputs\n",
    "        model_ouput = get_model_output(model, tokenizer, param_set, None, tf_valid_ds, None)\n",
    "\n",
    "        v_out = model_ouput['validation']['output']\n",
    "        ts_val=time.strftime(\"%Y%m%d_%H%M\")\n",
    "        print(ts_val)\n",
    "        write_model_output(validation, \"validation\", ts_val, v_out, write_path=exp_dir)\n",
    "\n",
    "        # Let's Use E2E Evaluation Metrics\n",
    "        scores = compute_metrics(exp_dir, base_dir, ts_val, 'validation', param_set)\n",
    "\n",
    "        print(scores)\n",
    "        print()\n",
    "        save_metrics(exp_dir, ts_val, scores)\n",
    "        param_count +=1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(model_size, opt_m, opt, learning_rate, encoder_max_len, decoder_max_len, epoch_num, tokenizer):\n",
    "    \"\"\"\n",
    "    Modularize Compute call in case of failures\n",
    "    \"\"\"\n",
    "    global metrics\n",
    "    global tf_train_ds\n",
    "    global tf_valid_ds\n",
    "    global steps\n",
    "    global valid_steps\n",
    "    global model_count\n",
    "    global fall_back_epochs\n",
    "    \n",
    "    print(f\"Computing Model ===> {model_count}\")\n",
    "\n",
    "    if 'model' in globals(): del model\n",
    "\n",
    "    #Compile Model\n",
    "    model = T5Wrapper.from_pretrained(model_size)\n",
    "    model.compile(optimizer=opt_m, metrics=metrics)\n",
    "    \n",
    "    #Handle epoch_num\n",
    "    ep = fall_back_epochs if epoch_num == \"NONE\" else epoch_num\n",
    "\n",
    "    #Model Fit\n",
    "    epochs_done=0\n",
    "    time_callback = TimeHistory()\n",
    "    \n",
    "    history_callback = model.fit(tf_train_ds, epochs=ep, steps_per_epoch=steps, callbacks=[time_callback],\n",
    "                                validation_data=tf_valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done)\n",
    "\n",
    "    #Call Backs Data\n",
    "    times = time_callback.times\n",
    "\n",
    "    #Data points \n",
    "    total_time = sum(times)\n",
    "    print(f\"Model Training Time: {total_time}\")\n",
    "\n",
    "    compute_generation(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-boards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-leadership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "graduate-master",
   "metadata": {},
   "source": [
    "## Kick it Off! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-cooperative",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\n",
    "model_count = 1\n",
    "\n",
    "for train_params in model_variants:\n",
    "\n",
    "    if 'tokenizer' in globals(): del tokenizer\n",
    "    if 'train_ds' in globals(): del train_ds\n",
    "    if 'valid_ds' in globals(): del valid_ds\n",
    "    if 'tf_train_ds' in globals(): del tf_train_ds\n",
    "    if 'tf_valid_ds' in globals(): del tf_valid_ds\n",
    "\n",
    "    opt = train_params['optimizer']\n",
    "    lr = train_params['lr_mod']\n",
    "    epoch_num = train_params.get('epoch_num', \"NONE\")\n",
    "    is_special_token = train_params['is_special_token']\n",
    "    encoder_max_len = train_params['encoder_max_len']\n",
    "    decoder_max_len = train_params['decoder_max_len']\n",
    "    model_size = train_params['model_size']\n",
    "    \n",
    "    print(f\"Model {model_count}/{len(model_variants)} opt: {opt}  lr: {lr} epoch_num: {epoch_num} encoder_max_len: {encoder_max_len} decoder_max_len: {decoder_max_len} is_special_token:{is_special_token}\")\n",
    "    \n",
    "    #Is Special Token\n",
    "    is_special = True if is_special_token =='yes' else False\n",
    "    \n",
    "    ### Init Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_size, additional_special_tokens=['data_to_text:']) if is_special else AutoTokenizer.from_pretrained(model_size)\n",
    "\n",
    "    ### Process Train/ Validation\n",
    "    train_ds = train.map(lambda x: encode(x, tokenizer, False, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len))\n",
    "    valid_ds = validation.map(lambda x: encode(x, tokenizer, False, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len))\n",
    "\n",
    "    ### Process Train/Validation =>  Tensors\n",
    "    tf_train_ds = to_tf_dataset(train_ds)\n",
    "    tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "\n",
    "    ### Build Train/ Validation =>  Model Ready Input\n",
    "    tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                     shuffling=True, cache_path = None)\n",
    "    tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                     shuffling=False, cache_path = None)\n",
    "\n",
    "    #### IF SOMETHING BREAKS PICKUP WHERE WE LEFT OFF\n",
    "#     if model_count < 152:\n",
    "#         print(f'Skipping: {model_count}')\n",
    "#         model_count +=1\n",
    "#         continue\n",
    "    ####\n",
    "\n",
    "    if opt == 'rmsprop':\n",
    "        opt_m = tf.keras.optimizers.RMSprop(lr)\n",
    "\n",
    "    elif opt == 'adam':\n",
    "        opt_m = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    elif opt == 'adagrad':\n",
    "        opt_m = tf.keras.optimizers.Adagrad(lr)\n",
    "\n",
    "    elif opt == 'adamax':\n",
    "        opt_m = tf.keras.optimizers.Adamax(lr)\n",
    "\n",
    "    elif opt == 'sgd':\n",
    "        opt_m = tf.keras.optimizers.SGD(lr)\n",
    "\n",
    "    try:\n",
    "        compute_model(model_size, opt_m, opt, lr, encoder_max_len, decoder_max_len, epoch_num, tokenizer)\n",
    "        model_count +=1\n",
    "    except:\n",
    "        print(f\"Failed on: Model#{model_count}\")\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-simpson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-portal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-senator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-runner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
