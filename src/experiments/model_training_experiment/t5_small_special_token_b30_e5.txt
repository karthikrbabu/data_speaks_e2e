["\nTraining: rmsprop ~~ with LR: 0.0005\nEpoch 1/5\n223/223 [==============================] - 80s 284ms/step - accuracy: 0.8782 - loss: 0.8223 - lr: 5.0000e-04 - val_accuracy: 0.9585 - val_loss: 0.5603\nEpoch 2/5\n223/223 [==============================] - 62s 278ms/step - accuracy: 0.9512 - loss: 0.5819 - lr: 5.0000e-04 - val_accuracy: 0.9626 - val_loss: 0.5187\nEpoch 3/5\n223/223 [==============================] - 63s 283ms/step - accuracy: 0.9554 - loss: 0.5573 - lr: 5.0000e-04 - val_accuracy: 0.9645 - val_loss: 0.5042\nEpoch 4/5\n223/223 [==============================] - 64s 288ms/step - accuracy: 0.9588 - loss: 0.5356 - lr: 5.0000e-04 - val_accuracy: 0.9657 - val_loss: 0.4878\nEpoch 5/5\n223/223 [==============================] - 65s 291ms/step - accuracy: 0.9608 - loss: 0.5188 - lr: 5.0000e-04 - val_accuracy: 0.9659 - val_loss: 0.4832\n    ", "\nTraining: adam ~~ with LR: 0.0005\nEpoch 1/5\n223/223 [==============================] - 79s 289ms/step - accuracy: 0.9141 - loss: 0.8353 - lr: 5.0000e-04 - val_accuracy: 0.9567 - val_loss: 0.5683\nEpoch 2/5\n223/223 [==============================] - 62s 279ms/step - accuracy: 0.9504 - loss: 0.5977 - lr: 5.0000e-04 - val_accuracy: 0.9594 - val_loss: 0.5346\nEpoch 3/5\n223/223 [==============================] - 63s 281ms/step - accuracy: 0.9544 - loss: 0.5685 - lr: 5.0000e-04 - val_accuracy: 0.9638 - val_loss: 0.5086\nEpoch 4/5\n223/223 [==============================] - 63s 283ms/step - accuracy: 0.9579 - loss: 0.5466 - lr: 5.0000e-04 - val_accuracy: 0.9647 - val_loss: 0.4963\nEpoch 5/5\n223/223 [==============================] - 63s 283ms/step - accuracy: 0.9594 - loss: 0.5302 - lr: 5.0000e-04 - val_accuracy: 0.9653 - val_loss: 0.4864\n    ", "\nTraining: adagrad ~~ with LR: 0.0005\nEpoch 1/5\n223/223 [==============================] - 78s 288ms/step - accuracy: 0.7418 - loss: 2.8145 - lr: 5.0000e-04 - val_accuracy: 0.8138 - val_loss: 1.7872\nEpoch 2/5\n223/223 [==============================] - 62s 278ms/step - accuracy: 0.7777 - loss: 2.0043 - lr: 5.0000e-04 - val_accuracy: 0.8366 - val_loss: 1.5564\nEpoch 3/5\n223/223 [==============================] - 62s 280ms/step - accuracy: 0.8106 - loss: 1.7381 - lr: 5.0000e-04 - val_accuracy: 0.8524 - val_loss: 1.4129\nEpoch 4/5\n223/223 [==============================] - 62s 280ms/step - accuracy: 0.8275 - loss: 1.5856 - lr: 5.0000e-04 - val_accuracy: 0.8650 - val_loss: 1.3107\nEpoch 5/5\n223/223 [==============================] - 62s 280ms/step - accuracy: 0.8404 - loss: 1.4802 - lr: 5.0000e-04 - val_accuracy: 0.8723 - val_loss: 1.2367\n    ", "\nTraining: adamax ~~ with LR: 0.0005\nEpoch 1/5\n223/223 [==============================] - 80s 293ms/step - accuracy: 0.8673 - loss: 1.0313 - lr: 5.0000e-04 - val_accuracy: 0.9411 - val_loss: 0.6932\nEpoch 2/5\n223/223 [==============================] - 63s 283ms/step - accuracy: 0.9296 - loss: 0.7364 - lr: 5.0000e-04 - val_accuracy: 0.9488 - val_loss: 0.6197\nEpoch 3/5\n223/223 [==============================] - 63s 285ms/step - accuracy: 0.9403 - loss: 0.6799 - lr: 5.0000e-04 - val_accuracy: 0.9537 - val_loss: 0.5873\nEpoch 4/5\n223/223 [==============================] - 64s 285ms/step - accuracy: 0.9454 - loss: 0.6411 - lr: 5.0000e-04 - val_accuracy: 0.9571 - val_loss: 0.5606\nEpoch 5/5\n223/223 [==============================] - 64s 285ms/step - accuracy: 0.9486 - loss: 0.6110 - lr: 5.0000e-04 - val_accuracy: 0.9589 - val_loss: 0.5439\n    ", "\nTraining: sgd ~~ with LR: 0.0005\nEpoch 1/5\n223/223 [==============================] - 77s 286ms/step - accuracy: 0.7619 - loss: 2.5759 - lr: 5.0000e-04 - val_accuracy: 0.8213 - val_loss: 1.6186\nEpoch 2/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.7971 - loss: 1.8195 - lr: 5.0000e-04 - val_accuracy: 0.8409 - val_loss: 1.4500\nEpoch 3/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.8209 - loss: 1.6339 - lr: 5.0000e-04 - val_accuracy: 0.8535 - val_loss: 1.3686\nEpoch 4/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.8323 - loss: 1.5260 - lr: 5.0000e-04 - val_accuracy: 0.8641 - val_loss: 1.3023\nEpoch 5/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.8407 - loss: 1.4590 - lr: 5.0000e-04 - val_accuracy: 0.8695 - val_loss: 1.2559\n    ", "\nTraining: rmsprop ~~ with LR: 0.0001\nEpoch 1/5\n223/223 [==============================] - 85s 304ms/step - accuracy: 0.8922 - loss: 0.8098 - lr: 5.0000e-04 - val_accuracy: 0.9580 - val_loss: 0.5582\nEpoch 2/5\n223/223 [==============================] - 66s 294ms/step - accuracy: 0.9519 - loss: 0.5814 - lr: 5.0000e-04 - val_accuracy: 0.9621 - val_loss: 0.5252\nEpoch 3/5\n223/223 [==============================] - 66s 296ms/step - accuracy: 0.9562 - loss: 0.5580 - lr: 5.0000e-04 - val_accuracy: 0.9642 - val_loss: 0.4998\nEpoch 4/5\n223/223 [==============================] - 66s 296ms/step - accuracy: 0.9590 - loss: 0.5341 - lr: 5.0000e-04 - val_accuracy: 0.9654 - val_loss: 0.4891\nEpoch 5/5\n223/223 [==============================] - 66s 296ms/step - accuracy: 0.9609 - loss: 0.5180 - lr: 5.0000e-04 - val_accuracy: 0.9660 - val_loss: 0.4840\n    ", "\nTraining: adam ~~ with LR: 0.0001\nEpoch 1/5\n223/223 [==============================] - 80s 292ms/step - accuracy: 0.9127 - loss: 0.8390 - lr: 5.0000e-04 - val_accuracy: 0.9569 - val_loss: 0.5710\nEpoch 2/5\n223/223 [==============================] - 63s 281ms/step - accuracy: 0.9493 - loss: 0.5986 - lr: 5.0000e-04 - val_accuracy: 0.9609 - val_loss: 0.5281\nEpoch 3/5\n223/223 [==============================] - 63s 282ms/step - accuracy: 0.9547 - loss: 0.5722 - lr: 5.0000e-04 - val_accuracy: 0.9634 - val_loss: 0.5050\nEpoch 4/5\n223/223 [==============================] - 63s 282ms/step - accuracy: 0.9581 - loss: 0.5457 - lr: 5.0000e-04 - val_accuracy: 0.9645 - val_loss: 0.4965\nEpoch 5/5\n223/223 [==============================] - 63s 282ms/step - accuracy: 0.9598 - loss: 0.5295 - lr: 5.0000e-04 - val_accuracy: 0.9653 - val_loss: 0.4917\n    ", "\nTraining: adagrad ~~ with LR: 0.0001\nEpoch 1/5\n223/223 [==============================] - 79s 287ms/step - accuracy: 0.7427 - loss: 2.8131 - lr: 5.0000e-04 - val_accuracy: 0.8130 - val_loss: 1.7897\nEpoch 2/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.7782 - loss: 1.9941 - lr: 5.0000e-04 - val_accuracy: 0.8357 - val_loss: 1.5119\nEpoch 3/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.8120 - loss: 1.7138 - lr: 5.0000e-04 - val_accuracy: 0.8561 - val_loss: 1.3487\nEpoch 4/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.8316 - loss: 1.5531 - lr: 5.0000e-04 - val_accuracy: 0.8684 - val_loss: 1.2666\nEpoch 5/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.8423 - loss: 1.4558 - lr: 5.0000e-04 - val_accuracy: 0.8755 - val_loss: 1.2030\n    ", "\nTraining: adamax ~~ with LR: 0.0001\nEpoch 1/5\n223/223 [==============================] - 79s 293ms/step - accuracy: 0.8703 - loss: 1.0199 - lr: 5.0000e-04 - val_accuracy: 0.9427 - val_loss: 0.6759\nEpoch 2/5\n223/223 [==============================] - 62s 279ms/step - accuracy: 0.9314 - loss: 0.7199 - lr: 5.0000e-04 - val_accuracy: 0.9507 - val_loss: 0.6060\nEpoch 3/5\n223/223 [==============================] - 63s 280ms/step - accuracy: 0.9413 - loss: 0.6671 - lr: 5.0000e-04 - val_accuracy: 0.9565 - val_loss: 0.5721\nEpoch 4/5\n223/223 [==============================] - 63s 281ms/step - accuracy: 0.9475 - loss: 0.6289 - lr: 5.0000e-04 - val_accuracy: 0.9584 - val_loss: 0.5515\nEpoch 5/5\n223/223 [==============================] - 63s 281ms/step - accuracy: 0.9497 - loss: 0.6018 - lr: 5.0000e-04 - val_accuracy: 0.9596 - val_loss: 0.5391\n    ", "\nTraining: sgd ~~ with LR: 0.0001\nEpoch 1/5\n223/223 [==============================] - 76s 284ms/step - accuracy: 0.7675 - loss: 2.5360 - lr: 5.0000e-04 - val_accuracy: 0.8234 - val_loss: 1.5915\nEpoch 2/5\n223/223 [==============================] - 60s 269ms/step - accuracy: 0.7991 - loss: 1.8029 - lr: 5.0000e-04 - val_accuracy: 0.8437 - val_loss: 1.4399\nEpoch 3/5\n223/223 [==============================] - 60s 271ms/step - accuracy: 0.8230 - loss: 1.6196 - lr: 5.0000e-04 - val_accuracy: 0.8551 - val_loss: 1.3503\nEpoch 4/5\n223/223 [==============================] - 61s 271ms/step - accuracy: 0.8340 - loss: 1.5174 - lr: 5.0000e-04 - val_accuracy: 0.8640 - val_loss: 1.2983\nEpoch 5/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8427 - loss: 1.4485 - lr: 5.0000e-04 - val_accuracy: 0.8702 - val_loss: 1.2500\n    ", "\nTraining: rmsprop ~~ with LR: 0.001\nEpoch 1/5\n223/223 [==============================] - 84s 303ms/step - accuracy: 0.8932 - loss: 0.8062 - lr: 5.0000e-04 - val_accuracy: 0.9574 - val_loss: 0.5610\nEpoch 2/5\n223/223 [==============================] - 64s 288ms/step - accuracy: 0.9530 - loss: 0.5790 - lr: 5.0000e-04 - val_accuracy: 0.9615 - val_loss: 0.5203\nEpoch 3/5\n223/223 [==============================] - 65s 289ms/step - accuracy: 0.9558 - loss: 0.5581 - lr: 5.0000e-04 - val_accuracy: 0.9634 - val_loss: 0.5061\nEpoch 4/5\n223/223 [==============================] - 65s 290ms/step - accuracy: 0.9583 - loss: 0.5358 - lr: 5.0000e-04 - val_accuracy: 0.9651 - val_loss: 0.4883\nEpoch 5/5\n223/223 [==============================] - 65s 290ms/step - accuracy: 0.9605 - loss: 0.5178 - lr: 5.0000e-04 - val_accuracy: 0.9661 - val_loss: 0.4806\n    ", "\nTraining: adam ~~ with LR: 0.001\nEpoch 1/5\n223/223 [==============================] - 78s 289ms/step - accuracy: 0.9124 - loss: 0.8455 - lr: 5.0000e-04 - val_accuracy: 0.9550 - val_loss: 0.5802\nEpoch 2/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.9490 - loss: 0.6038 - lr: 5.0000e-04 - val_accuracy: 0.9603 - val_loss: 0.5350\nEpoch 3/5\n223/223 [==============================] - 61s 276ms/step - accuracy: 0.9537 - loss: 0.5733 - lr: 5.0000e-04 - val_accuracy: 0.9629 - val_loss: 0.5150\nEpoch 4/5\n223/223 [==============================] - 61s 276ms/step - accuracy: 0.9572 - loss: 0.5480 - lr: 5.0000e-04 - val_accuracy: 0.9645 - val_loss: 0.5039\nEpoch 5/5\n223/223 [==============================] - 61s 276ms/step - accuracy: 0.9593 - loss: 0.5322 - lr: 5.0000e-04 - val_accuracy: 0.9652 - val_loss: 0.4963\n    ", "\nTraining: adagrad ~~ with LR: 0.001\nEpoch 1/5\n223/223 [==============================] - 76s 281ms/step - accuracy: 0.7418 - loss: 2.8174 - lr: 5.0000e-04 - val_accuracy: 0.8122 - val_loss: 1.7227\nEpoch 2/5\n223/223 [==============================] - 60s 270ms/step - accuracy: 0.7757 - loss: 2.0024 - lr: 5.0000e-04 - val_accuracy: 0.8323 - val_loss: 1.5177\nEpoch 3/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8096 - loss: 1.7371 - lr: 5.0000e-04 - val_accuracy: 0.8461 - val_loss: 1.4050\nEpoch 4/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8287 - loss: 1.5755 - lr: 5.0000e-04 - val_accuracy: 0.8605 - val_loss: 1.3132\nEpoch 5/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8381 - loss: 1.4797 - lr: 5.0000e-04 - val_accuracy: 0.8682 - val_loss: 1.2538\n    ", "\nTraining: adamax ~~ with LR: 0.001\nEpoch 1/5\n223/223 [==============================] - 77s 285ms/step - accuracy: 0.8704 - loss: 0.9979 - lr: 5.0000e-04 - val_accuracy: 0.9439 - val_loss: 0.6699\nEpoch 2/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.9317 - loss: 0.7165 - lr: 5.0000e-04 - val_accuracy: 0.9511 - val_loss: 0.6048\nEpoch 3/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.9421 - loss: 0.6633 - lr: 5.0000e-04 - val_accuracy: 0.9557 - val_loss: 0.5725\nEpoch 4/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.9476 - loss: 0.6271 - lr: 5.0000e-04 - val_accuracy: 0.9582 - val_loss: 0.5522\nEpoch 5/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.9496 - loss: 0.6019 - lr: 5.0000e-04 - val_accuracy: 0.9598 - val_loss: 0.5399\n    ", "\nTraining: sgd ~~ with LR: 0.001\nEpoch 1/5\n223/223 [==============================] - 75s 277ms/step - accuracy: 0.7638 - loss: 2.5788 - lr: 5.0000e-04 - val_accuracy: 0.8231 - val_loss: 1.5964\nEpoch 2/5\n223/223 [==============================] - 59s 266ms/step - accuracy: 0.7982 - loss: 1.8193 - lr: 5.0000e-04 - val_accuracy: 0.8433 - val_loss: 1.4477\nEpoch 3/5\n223/223 [==============================] - 60s 267ms/step - accuracy: 0.8210 - loss: 1.6276 - lr: 5.0000e-04 - val_accuracy: 0.8567 - val_loss: 1.3604\nEpoch 4/5\n223/223 [==============================] - 60s 268ms/step - accuracy: 0.8338 - loss: 1.5284 - lr: 5.0000e-04 - val_accuracy: 0.8668 - val_loss: 1.2988\nEpoch 5/5\n223/223 [==============================] - 60s 268ms/step - accuracy: 0.8423 - loss: 1.4541 - lr: 5.0000e-04 - val_accuracy: 0.8721 - val_loss: 1.2535\n    ", "\nTraining: rmsprop ~~ with LR: 0.005\nEpoch 1/5\n223/223 [==============================] - 83s 297ms/step - accuracy: 0.8902 - loss: 0.8317 - lr: 5.0000e-04 - val_accuracy: 0.9576 - val_loss: 0.5643\nEpoch 2/5\n223/223 [==============================] - 64s 286ms/step - accuracy: 0.9517 - loss: 0.5820 - lr: 5.0000e-04 - val_accuracy: 0.9624 - val_loss: 0.5181\nEpoch 3/5\n223/223 [==============================] - 64s 287ms/step - accuracy: 0.9552 - loss: 0.5574 - lr: 5.0000e-04 - val_accuracy: 0.9640 - val_loss: 0.5045\nEpoch 4/5\n223/223 [==============================] - 64s 288ms/step - accuracy: 0.9587 - loss: 0.5344 - lr: 5.0000e-04 - val_accuracy: 0.9653 - val_loss: 0.4861\nEpoch 5/5\n223/223 [==============================] - 64s 288ms/step - accuracy: 0.9607 - loss: 0.5176 - lr: 5.0000e-04 - val_accuracy: 0.9659 - val_loss: 0.4850\n    ", "\nTraining: adam ~~ with LR: 0.005\nEpoch 1/5\n223/223 [==============================] - 78s 285ms/step - accuracy: 0.9138 - loss: 0.8358 - lr: 5.0000e-04 - val_accuracy: 0.9553 - val_loss: 0.5732\nEpoch 2/5\n223/223 [==============================] - 61s 274ms/step - accuracy: 0.9489 - loss: 0.6006 - lr: 5.0000e-04 - val_accuracy: 0.9612 - val_loss: 0.5264\nEpoch 3/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.9545 - loss: 0.5713 - lr: 5.0000e-04 - val_accuracy: 0.9634 - val_loss: 0.5070\nEpoch 4/5\n223/223 [==============================] - 61s 276ms/step - accuracy: 0.9575 - loss: 0.5463 - lr: 5.0000e-04 - val_accuracy: 0.9649 - val_loss: 0.4932\nEpoch 5/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.9594 - loss: 0.5303 - lr: 5.0000e-04 - val_accuracy: 0.9661 - val_loss: 0.4884\n    ", "\nTraining: adagrad ~~ with LR: 0.005\nEpoch 1/5\n223/223 [==============================] - 77s 281ms/step - accuracy: 0.7438 - loss: 2.7947 - lr: 5.0000e-04 - val_accuracy: 0.8141 - val_loss: 1.7784\nEpoch 2/5\n223/223 [==============================] - 60s 270ms/step - accuracy: 0.7777 - loss: 1.9965 - lr: 5.0000e-04 - val_accuracy: 0.8384 - val_loss: 1.5396\nEpoch 3/5\n223/223 [==============================] - 60s 271ms/step - accuracy: 0.8117 - loss: 1.7320 - lr: 5.0000e-04 - val_accuracy: 0.8550 - val_loss: 1.4042\nEpoch 4/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8298 - loss: 1.5720 - lr: 5.0000e-04 - val_accuracy: 0.8669 - val_loss: 1.2992\nEpoch 5/5\n223/223 [==============================] - 61s 273ms/step - accuracy: 0.8415 - loss: 1.4718 - lr: 5.0000e-04 - val_accuracy: 0.8745 - val_loss: 1.2243\n    ", "\nTraining: adamax ~~ with LR: 0.005\nEpoch 1/5\n223/223 [==============================] - 78s 286ms/step - accuracy: 0.8743 - loss: 0.9884 - lr: 5.0000e-04 - val_accuracy: 0.9438 - val_loss: 0.6619\nEpoch 2/5\n223/223 [==============================] - 61s 274ms/step - accuracy: 0.9340 - loss: 0.7064 - lr: 5.0000e-04 - val_accuracy: 0.9516 - val_loss: 0.6007\nEpoch 3/5\n223/223 [==============================] - 61s 276ms/step - accuracy: 0.9423 - loss: 0.6588 - lr: 5.0000e-04 - val_accuracy: 0.9572 - val_loss: 0.5659\nEpoch 4/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.9474 - loss: 0.6209 - lr: 5.0000e-04 - val_accuracy: 0.9584 - val_loss: 0.5467\nEpoch 5/5\n223/223 [==============================] - 62s 277ms/step - accuracy: 0.9502 - loss: 0.5987 - lr: 5.0000e-04 - val_accuracy: 0.9598 - val_loss: 0.5335\n    ", "\nTraining: sgd ~~ with LR: 0.005\nEpoch 1/5\n223/223 [==============================] - 75s 280ms/step - accuracy: 0.7625 - loss: 2.5975 - lr: 5.0000e-04 - val_accuracy: 0.8215 - val_loss: 1.6164\nEpoch 2/5\n223/223 [==============================] - 59s 265ms/step - accuracy: 0.7968 - loss: 1.8273 - lr: 5.0000e-04 - val_accuracy: 0.8407 - val_loss: 1.4576\nEpoch 3/5\n223/223 [==============================] - 59s 267ms/step - accuracy: 0.8204 - loss: 1.6350 - lr: 5.0000e-04 - val_accuracy: 0.8540 - val_loss: 1.3722\nEpoch 4/5\n223/223 [==============================] - 60s 268ms/step - accuracy: 0.8340 - loss: 1.5304 - lr: 5.0000e-04 - val_accuracy: 0.8643 - val_loss: 1.3061\nEpoch 5/5\n223/223 [==============================] - 60s 269ms/step - accuracy: 0.8405 - loss: 1.4644 - lr: 5.0000e-04 - val_accuracy: 0.8701 - val_loss: 1.2607\n    ", "\nTraining: rmsprop ~~ with LR: custom\nEpoch 1/5\n223/223 [==============================] - 83s 297ms/step - accuracy: 0.8919 - loss: 0.8169 - lr: 5.0000e-04 - val_accuracy: 0.9583 - val_loss: 0.5578\nEpoch 2/5\n223/223 [==============================] - 64s 286ms/step - accuracy: 0.9519 - loss: 0.5808 - lr: 5.0000e-04 - val_accuracy: 0.9624 - val_loss: 0.5240\nEpoch 3/5\n223/223 [==============================] - 64s 288ms/step - accuracy: 0.9560 - loss: 0.5598 - lr: 5.0000e-04 - val_accuracy: 0.9644 - val_loss: 0.5004\nEpoch 4/5\n223/223 [==============================] - 64s 289ms/step - accuracy: 0.9589 - loss: 0.5324 - lr: 5.0000e-04 - val_accuracy: 0.9660 - val_loss: 0.4902\nEpoch 5/5\n223/223 [==============================] - 64s 289ms/step - accuracy: 0.9599 - loss: 0.5204 - lr: 5.0000e-04 - val_accuracy: 0.9659 - val_loss: 0.4838\n    ", "\nTraining: adam ~~ with LR: custom\nEpoch 1/5\n223/223 [==============================] - 79s 285ms/step - accuracy: 0.9133 - loss: 0.8427 - lr: 5.0000e-04 - val_accuracy: 0.9561 - val_loss: 0.5702\nEpoch 2/5\n223/223 [==============================] - 61s 274ms/step - accuracy: 0.9496 - loss: 0.6005 - lr: 5.0000e-04 - val_accuracy: 0.9606 - val_loss: 0.5305\nEpoch 3/5\n223/223 [==============================] - 61s 275ms/step - accuracy: 0.9545 - loss: 0.5710 - lr: 5.0000e-04 - val_accuracy: 0.9634 - val_loss: 0.5071\nEpoch 4/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.9566 - loss: 0.5458 - lr: 5.0000e-04 - val_accuracy: 0.9645 - val_loss: 0.4972\nEpoch 5/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.9591 - loss: 0.5315 - lr: 5.0000e-04 - val_accuracy: 0.9663 - val_loss: 0.4879\n    ", "\nTraining: adagrad ~~ with LR: custom\nEpoch 1/5\n223/223 [==============================] - 77s 285ms/step - accuracy: 0.7400 - loss: 2.8461 - lr: 5.0000e-04 - val_accuracy: 0.8118 - val_loss: 1.7928\nEpoch 2/5\n223/223 [==============================] - 60s 271ms/step - accuracy: 0.7767 - loss: 2.0115 - lr: 5.0000e-04 - val_accuracy: 0.8351 - val_loss: 1.5420\nEpoch 3/5\n223/223 [==============================] - 61s 272ms/step - accuracy: 0.8126 - loss: 1.7276 - lr: 5.0000e-04 - val_accuracy: 0.8537 - val_loss: 1.3848\nEpoch 4/5\n223/223 [==============================] - 61s 274ms/step - accuracy: 0.8305 - loss: 1.5745 - lr: 5.0000e-04 - val_accuracy: 0.8669 - val_loss: 1.2818\nEpoch 5/5\n223/223 [==============================] - 61s 274ms/step - accuracy: 0.8426 - loss: 1.4651 - lr: 5.0000e-04 - val_accuracy: 0.8744 - val_loss: 1.2111    \n    ", "\nTraining: adamax ~~ with LR: custom\nEpoch 1/5\n223/223 [==============================] - 78s 291ms/step - accuracy: 0.8726 - loss: 1.0047 - lr: 5.0000e-04 - val_accuracy: 0.9430 - val_loss: 0.6742\nEpoch 2/5\n223/223 [==============================] - 62s 276ms/step - accuracy: 0.9325 - loss: 0.7134 - lr: 5.0000e-04 - val_accuracy: 0.9506 - val_loss: 0.6076\nEpoch 3/5\n223/223 [==============================] - 62s 278ms/step - accuracy: 0.9409 - loss: 0.6669 - lr: 5.0000e-04 - val_accuracy: 0.9564 - val_loss: 0.5685\nEpoch 4/5\n223/223 [==============================] - 62s 278ms/step - accuracy: 0.9474 - loss: 0.6258 - lr: 5.0000e-04 - val_accuracy: 0.9590 - val_loss: 0.5516\nEpoch 5/5\n223/223 [==============================] - 62s 279ms/step - accuracy: 0.9502 - loss: 0.6043 - lr: 5.0000e-04 - val_accuracy: 0.9598 - val_loss: 0.5353    \n    ", "\nTraining: sgd ~~ with LR: custom\nEpoch 1/5\n223/223 [==============================] - 76s 279ms/step - accuracy: 0.7649 - loss: 2.5622 - lr: 5.0000e-04 - val_accuracy: 0.8216 - val_loss: 1.6188\nEpoch 2/5\n223/223 [==============================] - 60s 268ms/step - accuracy: 0.7974 - loss: 1.8187 - lr: 5.0000e-04 - val_accuracy: 0.8425 - val_loss: 1.4519\nEpoch 3/5\n223/223 [==============================] - 60s 270ms/step - accuracy: 0.8220 - loss: 1.6217 - lr: 5.0000e-04 - val_accuracy: 0.8564 - val_loss: 1.3585\nEpoch 4/5\n223/223 [==============================] - 60s 271ms/step - accuracy: 0.8335 - loss: 1.5245 - lr: 5.0000e-04 - val_accuracy: 0.8651 - val_loss: 1.2975\nEpoch 5/5\n223/223 [==============================] - 60s 271ms/step - accuracy: 0.8406 - loss: 1.4601 - lr: 5.0000e-04 - val_accuracy: 0.8707 - val_loss: 1.2551    \n    "]