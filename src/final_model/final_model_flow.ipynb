{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorrect-webcam",
   "metadata": {},
   "source": [
    "# Final Model Iteration\n",
    "\n",
    "The purpose of this notebook is to showcase the best model and generation experiment we have achieved through our research.\n",
    "\n",
    "#### Steps:\n",
    "* Import Libraries\n",
    "* Load Train/Dev/Test Data\n",
    "* Config Definitions\n",
    "* Pre-process Data (Tensors)\n",
    "* Quick Tensor EDA\n",
    "* Optimizer Init\n",
    "* Train TF T5 on E2E Cleaned Data to Text Problem\n",
    "* Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-powell",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import traceback\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "#NLTK \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "#HuggingFace\n",
    "import transformers\n",
    "from transformers import (TFAutoModelWithLMHead, AutoTokenizer,\n",
    "                            TFTrainer, TFTrainingArguments, T5Tokenizer, TFT5ForConditionalGeneration,\n",
    "                            TFT5Model, T5Config, pipeline)\n",
    "import datasets\n",
    "from datasets import load_dataset, list_datasets\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "#AWS\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.getcwd()\n",
    "print(\"Experiment Dir: \", exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir, os.pardir))\n",
    "os.chdir(base_dir)\n",
    "print(\"Base Dir: \", base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Utils Lib\n",
    "from src.utils.utils import (get_model_output, write_model_output, save_metrics,\n",
    "                         encode, to_tf_dataset, create_dataset, compute_metrics, save_model_to_s3)\n",
    "from src.classes.t5Wrapper import T5Wrapper\n",
    "from src.classes.customScheduler import CustomSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)\n",
    "\n",
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-powder",
   "metadata": {},
   "source": [
    "### Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS box path we should keep\n",
    "tb_data_dir = f\"{exp_dir}/tf_data\"\n",
    "log_dir = f\"{tb_data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{tb_data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{tb_data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{tb_data_dir}/cache/t5.test\"\n",
    "\n",
    "print(\"Experiment Base directory: \",exp_dir)\n",
    "model_path = f'{exp_dir}/model'\n",
    "print('model_path: ', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-jimmy",
   "metadata": {},
   "source": [
    "### Load Train + Validation + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('e2e_nlg_cleaned', split='train')\n",
    "validation = load_dataset('e2e_nlg_cleaned', split='validation')\n",
    "test = load_dataset('e2e_nlg_cleaned', split='test')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-narrative",
   "metadata": {},
   "source": [
    "### Init Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_back_epochs = 5\n",
    "batch_size = 30\n",
    "buffer_size = 1000\n",
    "ntrain = len(train)\n",
    "nvalid = len(validation)\n",
    "steps = int((ntrain//fall_back_epochs)// batch_size)\n",
    "valid_steps = int((nvalid//fall_back_epochs)// batch_size)\n",
    "\n",
    "print(\"Train Data Length: \", ntrain)\n",
    "print(\"Validation Data Length: \", nvalid)\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "print(\"Total fall_back_epochs: \", fall_back_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-cannon",
   "metadata": {},
   "source": [
    "### Model Variants and Param Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-edwards",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "path = f'{base_dir}/src/experiments/model_training_experiment/exp_chpt/result_271.txt'\n",
    "with open(path) as json_file:\n",
    "    models_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-survey",
   "metadata": {},
   "source": [
    "### Model Variants\n",
    "\n",
    "From all the variants we have tried, we found that model ID `82` gave us the best performance. Please refer to the notebook found in `data_speaks_e2e/src/experiments/model_training_experiment` to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_id = 82\n",
    "model_variants = [model for model in models_data if model['id'] == best_model_id]\n",
    "model_variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-purple",
   "metadata": {},
   "source": [
    "### Param Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = [ \n",
    "    {'num_beams': 5, \n",
    "     'max_length': 220, \n",
    "     'min_length': 20, \n",
    "     'early_stopping': False, \n",
    "     'do_sample': False, \n",
    "     'no_repeat_ngram_size': 2},\n",
    "\n",
    "    {'num_beams': 5,\n",
    "     'max_length': 45, \n",
    "     'min_length': 10, \n",
    "     'early_stopping': False, \n",
    "     'do_sample': False, \n",
    "     'no_repeat_ngram_size': 2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of param_sets: \", len(param_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_generation(model, tokenizer):\n",
    "    global tf_valid_ds\n",
    "    global tf_test_ds\n",
    "    global validation\n",
    "    global test\n",
    "    global exp_dir\n",
    "    global base_dir\n",
    "    global param_sets\n",
    "    \n",
    "    print(\"Starting Generate Variants:\")\n",
    "    param_count = 1\n",
    "    for param_set in param_sets:\n",
    "\n",
    "        print(f\"Generate {param_count}/{len(param_sets)}\")\n",
    "        print(str(param_set))\n",
    "\n",
    "        #Returns a dictionary for model output for test \n",
    "        model_ouput = get_model_output(model, tokenizer, param_set, None, None, tf_test_ds)\n",
    "\n",
    "        #Test Out\n",
    "        test_out = model_ouput['test']['output']\n",
    "        ts_val=time.strftime(\"%Y%m%d_%H%M\")\n",
    "        print(ts_val)\n",
    "        write_model_output(test, \"test\", ts_val, test_out, write_path=exp_dir)\n",
    "\n",
    "        # Let's Use E2E Evaluation Metrics\n",
    "        scores = compute_metrics(exp_dir, base_dir, ts_val, 'test', param_set)\n",
    "\n",
    "        print(scores)\n",
    "        print()\n",
    "        save_metrics(exp_dir, ts_val, scores)\n",
    "        \n",
    "        \n",
    "        param_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(model_size, opt_m, opt, learning_rate, encoder_max_len, decoder_max_len, epoch_num, tokenizer):\n",
    "    \"\"\"\n",
    "    Modularize Compute call in case of failures\n",
    "    \"\"\"\n",
    "    global metrics\n",
    "    global tf_train_ds\n",
    "    global tf_valid_ds\n",
    "    global steps\n",
    "    global valid_steps\n",
    "    global model_count\n",
    "    global fall_back_epochs\n",
    "    global model\n",
    "    \n",
    "    print(f\"Computing Model ===> {model_count}\")\n",
    "\n",
    "    if 'model' not in globals():\n",
    "        \n",
    "        print(\"TRAINING A MODEL\")\n",
    "        #Compile Model\n",
    "        model = T5Wrapper.from_pretrained(model_size)\n",
    "    \n",
    "        model.compile(optimizer=opt_m, metrics=metrics)\n",
    "\n",
    "        #Handle epoch_num\n",
    "        ep = fall_back_epochs if epoch_num == \"NONE\" else epoch_num\n",
    "\n",
    "        #Model Fit\n",
    "        epochs_done=0\n",
    "        time_callback = TimeHistory()\n",
    "\n",
    "        history_callback = model.fit(tf_train_ds, epochs=ep, steps_per_epoch=steps, callbacks=[time_callback],\n",
    "                                    validation_data=tf_valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done)\n",
    "\n",
    "        #Call Backs Data\n",
    "        times = time_callback.times\n",
    "\n",
    "        #Data points \n",
    "        total_time = sum(times)\n",
    "        print(f\"Model Training Time: {total_time}\")\n",
    "\n",
    "    else:\n",
    "        print(\"GRABBING THE MODEL\")\n",
    "\n",
    "    #This is computed both on the validation and test data\n",
    "    compute_generation(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-hometown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-wales",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "several-movie",
   "metadata": {},
   "source": [
    "## Kick it Off! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = model_variants[0]\n",
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-wedding",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\n",
    "model_count = 1\n",
    "\n",
    "####\n",
    "# Using already trained model\n",
    "model = T5Wrapper.from_pretrained(f'{exp_dir}/model')\n",
    "###\n",
    "\n",
    "#Grab all Model details from config\n",
    "opt = train_params['optimizer']\n",
    "lr = train_params['lr_mod']\n",
    "epoch_num = train_params.get('epoch_num', \"NONE\")\n",
    "is_special_token = train_params['is_special_token']\n",
    "encoder_max_len = train_params['encoder_max_len']\n",
    "decoder_max_len = train_params['decoder_max_len']\n",
    "model_size = train_params['model_size']\n",
    "\n",
    "print(f\"Model {model_count} opt: {opt}  lr: {lr} epoch_num: {epoch_num} encoder_max_len: {encoder_max_len} decoder_max_len: {decoder_max_len} is_special_token:{is_special_token}\")\n",
    "\n",
    "#Is Special Token\n",
    "is_special = True if is_special_token =='yes' else False\n",
    "\n",
    "### Init Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_size, additional_special_tokens=['data_to_text:']) if is_special else AutoTokenizer.from_pretrained(model_size)\n",
    "\n",
    "### Process Train/ Validation\n",
    "train_ds = train.map(lambda x: encode(x, tokenizer, False, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len))\n",
    "valid_ds = validation.map(lambda x: encode(x, tokenizer, False, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len))\n",
    "test_ds = test.map(lambda x: encode(x, tokenizer, False, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len))\n",
    "\n",
    "### Process Train/Validation =>  Tensors\n",
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "tf_test_ds = to_tf_dataset(test_ds)\n",
    "\n",
    "### Build Train/ Validation =>  Model Ready Input\n",
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                 shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                 shuffling=False, cache_path = None)\n",
    "tf_test_ds = create_dataset(tf_test_ds, batch_size=batch_size, \n",
    "                 shuffling=False, cache_path = None)\n",
    "\n",
    "if opt == 'rmsprop':\n",
    "    opt_m = tf.keras.optimizers.RMSprop(lr)\n",
    "\n",
    "elif opt == 'adam':\n",
    "    opt_m = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "elif opt == 'adagrad':\n",
    "    opt_m = tf.keras.optimizers.Adagrad(lr)\n",
    "\n",
    "elif opt == 'adamax':\n",
    "    opt_m = tf.keras.optimizers.Adamax(lr)\n",
    "\n",
    "elif opt == 'sgd':\n",
    "    opt_m = tf.keras.optimizers.SGD(lr)\n",
    "\n",
    "try:\n",
    "    compute_model(model_size, opt_m, opt, lr, encoder_max_len, decoder_max_len, epoch_num, tokenizer)\n",
    "    model_count +=1\n",
    "except:\n",
    "    print(f\"Failed on: Model: #{model_count}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-skating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-irish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
